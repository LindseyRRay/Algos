{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOBe7aH/p5NT9VKU/Z7spTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LindseyRRay/Algos/blob/master/colab/ChatDecisionCurve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDd5WC4bHPke",
        "outputId": "c4b90197-1d4b-41cb-e555-44c7eba6e5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Collecting isoweek\n",
            "  Downloading isoweek-1.3.3-py2.py3-none-any.whl (7.1 kB)\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting import_ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.9.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, isoweek, ipython-autotime, import-ipynb, funcy\n",
            "Successfully installed funcy-1.17 import-ipynb-0.1.4 ipython-autotime-0.3.1 isoweek-1.3.3 jedi-0.18.1\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Cresta\n",
            "Python 3.7.13\n",
            "time: 121 ms (started: 2022-09-09 18:18:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install funcy pandas numpy matplotlib seaborn isoweek ipython-autotime import_ipynb\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## Navigate to collab notebook and import function\n",
        "# https://colab.research.google.com/drive/1nta1E1GbvWw0NknSNhpMPrH39af3HMhj\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/Cresta\"\n",
        "\n",
        "\n",
        "import json\n",
        "import funcy\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import isoweek\n",
        "\n",
        "import datetime\n",
        "\n",
        "\n",
        "#import colab_data_construction_helpers\n",
        "import colab_config\n",
        "import colab_data_construction_helpers\n",
        "\n",
        "%load_ext autotime\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colab_config import (production_files_dir, cleaned_production_filename, analytics_files_dir, clean_analytics_files_dir, \n",
        "                          topic_counts_filename, analytics_manager_transfer_dir, merged_files_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIlZLeudHsbh",
        "outputId": "25112d59-b6f1-453d-91a8-d7a127ad4e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 703 µs (started: 2022-09-09 18:18:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_files = sorted([x for x in os.listdir(merged_files_dir) if x.endswith('.csv') and x.startswith('intuitCS')])\n",
        "print(analytics_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjK7kW3dH0uK",
        "outputId": "08cc7bf2-25b2-45ad-dd4c-e3c8900ae83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['intuitCS_anaprod_12March2022_1.csv', 'intuitCS_anaprod_12March2022_2.csv', 'intuitCS_anaprod_12March2022_3.csv', 'intuitCS_anaprod_12March2022_4.csv', 'intuitCS_anaprod_12March2022_5.csv', 'intuitCS_anaprod_12March2022_6.csv', 'intuitCS_anaprod_12March2022_7.csv', 'intuitCS_anaprod_12March2022_8.csv']\n",
            "time: 3.95 s (started: 2022-09-09 18:18:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_subset = ['flag_manager', 'flag_transfer', 'flag_deleted', 'flag_manualclose', 'flag_closeagent', 'universal_agent_username',\n",
        "    'flag_notpartial', 'chat_month_date','platform_chat_skillname', 'flag_ai_on_mindate', 'chat_duration_minutes',  'flag_manualclose',\n",
        "    'flag_closeagent',  'flag_notpartial',  'flag_deleted', \n",
        "    'flag_resolved',  'number_kb_suggestions',  'total_number_hints', 'n_suggestions_shown', 'disinct_hints',  'receptivity']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G90vkcbw_U7g",
        "outputId": "87ef3082-b339-4781-fb37-4aa23922bf22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 869 µs (started: 2022-09-09 18:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for i in analytics_files[3:8]:\n",
        "    print(i)\n",
        "    print(os.path.join(merged_files_dir, i))\n",
        "    t = pd.read_csv(os.path.join(merged_files_dir, i), usecols=col_subset)\n",
        "    print('original df shape:', t.shape)\n",
        "    dfs.append(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK1aF8iWwlsM",
        "outputId": "4ad83bfa-0a0b-4044-cc1e-4f1859a7d10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intuitCS_anaprod_12March2022_4.csv\n",
            "/content/drive/MyDrive/Research/Cresta/Data/IntData/merged/merged_prod_ana/intuitCS_anaprod_12March2022_4.csv\n",
            "original df shape: (620292, 17)\n",
            "intuitCS_anaprod_12March2022_5.csv\n",
            "/content/drive/MyDrive/Research/Cresta/Data/IntData/merged/merged_prod_ana/intuitCS_anaprod_12March2022_5.csv\n",
            "original df shape: (583967, 17)\n",
            "intuitCS_anaprod_12March2022_6.csv\n",
            "/content/drive/MyDrive/Research/Cresta/Data/IntData/merged/merged_prod_ana/intuitCS_anaprod_12March2022_6.csv\n",
            "original df shape: (270907, 17)\n",
            "intuitCS_anaprod_12March2022_7.csv\n",
            "/content/drive/MyDrive/Research/Cresta/Data/IntData/merged/merged_prod_ana/intuitCS_anaprod_12March2022_7.csv\n",
            "original df shape: (406824, 17)\n",
            "intuitCS_anaprod_12March2022_8.csv\n",
            "/content/drive/MyDrive/Research/Cresta/Data/IntData/merged/merged_prod_ana/intuitCS_anaprod_12March2022_8.csv\n",
            "original df shape: (99201, 17)\n",
            "time: 7min 47s (started: 2022-09-09 18:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.concat(dfs, axis=0, sort=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arp2dJiuiXGh",
        "outputId": "88533ae7-6b0b-4d19-f2cb-604c8ecd7df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 872 ms (started: 2022-09-09 18:31:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXid-1OTFIDr",
        "outputId": "ee792c83-9394-4400-9710-3d6e0d2d0a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76848\n",
            "202549\n",
            "time: 208 ms (started: 2022-09-09 18:31:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_skillname_rank(df, output_filename, to_groupby=None, min_chats=0):\n",
        "    if to_groupby is None:\n",
        "        to_groupby = ['chat_month_date','platform_chat_skillname']\n",
        "    print('Grouping by: ', to_groupby)\n",
        "    analysis_columns = ['chat_duration_minutes', 'flag_manager', 'flag_transfer', 'flag_manualclose', 'flag_closeagent',  'flag_notpartial', 'flag_deleted', \n",
        "                        'flag_binary_transfer', 'flag_binary_manager', 'number_kb_suggestions', 'total_number_hints', 'n_suggestions_shown', 'disinct_hints', 'receptivity']\n",
        "    df.loc[:, analysis_columns] = df[analysis_columns].fillna(0)\n",
        "    df['flag_binary_manager'] = 0\n",
        "    mask = (df['flag_manager'] > 0)\n",
        "    df.loc[mask, 'flag_binary_manager'] = 1\n",
        "    print(df['flag_binary_manager'].sum())\n",
        "    df['flag_binary_transfer'] = 0\n",
        "    mask = (df['flag_transfer'] > 0)\n",
        "    df.loc[mask, 'flag_binary_transfer'] = 1\n",
        "    print(df['flag_binary_transfer'].sum())\n",
        "    \n",
        "    pre_ai_counts = df.groupby(to_groupby).agg({'platform_chat_skillname': 'count',\n",
        "                                                                               'chat_duration_minutes': np.mean,\n",
        "                                                                               'flag_manager': np.mean,\n",
        "                                                                               'flag_transfer': np.mean,\n",
        "                                                                               'flag_manualclose': np.mean,\n",
        "                                                                               'flag_closeagent': np.mean,\n",
        "                                                                               'flag_notpartial': np.mean,\n",
        "                                                                               'flag_deleted': np.mean, \n",
        "                                                                                'flag_binary_transfer': np.mean,\n",
        "                                                                               'flag_binary_manager': np.mean,\n",
        "                                                                                'number_kb_suggestions': np.mean,\n",
        "                                                                               'total_number_hints': np.mean,\n",
        "                                                                               'n_suggestions_shown': np.mean,\n",
        "                                                                               'disinct_hints': np.mean,\n",
        "                                                                               'receptivity': np.mean})\n",
        "    \n",
        "    pre_ai_counts = pre_ai_counts.rename(columns={'platform_chat_skillname':'count_chats'}).reset_index()\n",
        "    pre_ai_counts['number_months'] = pre_ai_counts.groupby('platform_chat_skillname')['chat_month_date'].transform('count')\n",
        "    ## drop if number of chats in a given month-category below a certain threshold\n",
        "    mask = (pre_ai_counts['count_chats']>min_chats)\n",
        "    print(sum(mask))\n",
        "    pre_ai_counts2 = pre_ai_counts.loc[mask, :].copy()\n",
        "    print('Pre filter : ', pre_ai_counts.shape, ' post filter ', pre_ai_counts2.shape)\n",
        "    pre_ai_counts2['rank_chats'] = pre_ai_counts2.groupby(['chat_month_date'])['count_chats'].rank(ascending=False, method='min')\n",
        "\n",
        "    #pre_ai_counts2['rank_duration'] = pre_ai_counts2.groupby(['chat_month_date'])['chat_duration_minutes'].rank(ascending=True, method='min')\n",
        "\n",
        "    ## break thse into buckets by month, quarters\n",
        "    #df.groupby('country')[['value']].transform(lambda x: pd.cut(x, bins = 2).astype(str)\n",
        "    #pre_ai_counts2['quantile_chat_ranks'] = pre_ai_counts2.groupby('chat_month_date')['count_chats'].transform(lambda x: pd.qcut(x, q=5, labels=['q0', 'q1', 'q2', 'q3', 'q4']))\n",
        "\n",
        "    print('Saving to ', output_filename)\n",
        "    pre_ai_counts2.to_csv(output_filename, index=False)\n",
        "    return pre_ai_counts2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBP5Ho2XhZ-f",
        "outputId": "5c611661-2392-4fd7-8d2f-168bc1d29eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.91 ms (started: 2022-09-09 18:32:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_ai_counts = compute_skillname_rank(df1, '/content/drive/MyDrive/Research/Cresta/Data/IntData/chats/chat_ranks_all.csv',\n",
        "                                    ['chat_month_date','platform_chat_skillname', 'flag_ai_on_mindate'], min_chats=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHLESvPViN6l",
        "outputId": "3e01abc7-7f63-459d-ecb5-ec43bd10a05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grouping by:  ['chat_month_date', 'platform_chat_skillname', 'flag_ai_on_mindate']\n",
            "76848\n",
            "202549\n",
            "1591\n",
            "Pre filter :  (2211, 19)  post filter  (1591, 19)\n",
            "Saving to  /content/drive/MyDrive/Research/Cresta/Data/IntData/chats/chat_ranks_all.csv\n",
            "time: 2.59 s (started: 2022-09-09 18:32:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_ai_counts = compute_skillname_rank(df1, '/content/drive/MyDrive/Research/Cresta/Data/IntData/chats/chat_ranks_agents.csv',\n",
        "                                    ['chat_month_date','platform_chat_skillname', 'flag_ai_on_mindate', 'universal_agent_username'], min_chats=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0kR9Y6n648t",
        "outputId": "cb47d965-1c1e-47b6-d25f-53adc30e22d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grouping by:  ['chat_month_date', 'platform_chat_skillname', 'flag_ai_on_mindate', 'universal_agent_username']\n",
            "76848\n",
            "202549\n",
            "86075\n",
            "Pre filter :  (86075, 20)  post filter  (86075, 20)\n",
            "Saving to  /content/drive/MyDrive/Research/Cresta/Data/IntData/chats/chat_ranks_agents.csv\n",
            "time: 4.14 s (started: 2022-09-09 18:32:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZvILL8miZK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2opPUNVAiZPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUgerGIdiZUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Nmhh_jHIZzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis Using the Production Dataset"
      ],
      "metadata": {
        "id": "RER1D5fKe1Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Reading in production from :', cleaned_production_filename)\n",
        "prod_df2 = colab_data_construction_helpers.get_prod_df(create_df=False, cleaned_production_filename=colab_config.cleaned_production_filename)\n",
        "\n",
        "fill_missing_columns = ['duration_minutes', 'n_messages_visitor', 'n_messages_agent', 'number_messages','n_suggestions_shown',\n",
        " 'flag_transfer', 'flag_manager',  'flag_resolved', 'number_kb_suggestions', 'receptivity',\n",
        " 'n_followed_hints',  'scored_hints', 'inactivity_hints',  'guidance_hints',\n",
        " 'positive_reinforce_hints',  'proactive_hints', 'react_game_hints',\n",
        " 'flag_receptive_noninactive',  'total_number_hints',\n",
        " 'disinct_hints',  'flag_agent_duplicated', 'sc_suggestions_used', 'sc_ai_used',\n",
        " 'sc_coach_used', 'number_sc_inserted',  'number_instantsend_suggestions']\n",
        "\n",
        "prod_df2.loc[:, fill_missing_columns] = prod_df2.loc[:, fill_missing_columns].fillna(0)\n",
        "\n",
        "prod_df2['flag_binary_manager'] = 0\n",
        "mask = (prod_df2['flag_manager'] > 0)\n",
        "prod_df2.loc[mask, 'flag_binary_manager'] = 1\n",
        "print(prod_df2['flag_binary_manager'].sum())\n",
        "prod_df2['flag_binary_transfer'] = 0\n",
        "mask = (prod_df2['flag_transfer'] > 0)\n",
        "prod_df2.loc[mask, 'flag_binary_transfer'] = 1\n",
        "print(prod_df2['flag_binary_transfer'].sum())\n",
        "\n",
        "prod_df2[['flag_binary_transfer', 'flag_binary_manager']].mean()\n",
        "\n",
        "\n",
        "post_ai_counts = prod_df2.loc[(prod_df2['flag_ai_on_mindate']>0),:].groupby(['chat_month_date','platform_chat_skill']).agg({'platform_chat_skill': 'count',\n",
        "                                                                               'duration_minutes': np.mean,\n",
        "                                                                               'flag_resolved': np.mean,\n",
        "                                                                               'number_kb_suggestions': np.mean,\n",
        "                                                                               'total_number_hints': np.mean,\n",
        "                                                                               'n_suggestions_shown': np.mean,\n",
        "                                                                               'flag_manager': np.mean,\n",
        "                                                                               'flag_transfer': np.mean,\n",
        "                                                                               'disinct_hints': np.mean,\n",
        "                                                                               'receptivity': np.mean, \n",
        "                                                                               'flag_binary_transfer': np.mean,\n",
        "                                                                               'flag_binary_manager': np.mean,})\n",
        "\n",
        "post_ai_counts = post_ai_counts.rename(columns={'platform_chat_skill':'count_chats'}).reset_index()\n",
        "post_ai_counts['number_months'] = post_ai_counts.groupby('platform_chat_skill')['chat_month_date'].transform('count')\n",
        "## drop if number of chats in a given month-category below a certain threshold\n",
        "mask = (post_ai_counts['count_chats']>5)\n",
        "print(sum(mask))\n",
        "post_ai_counts2 = post_ai_counts.loc[mask, :].copy()\n",
        "print('Pre filter : ', post_ai_counts.shape, ' post filter ', post_ai_counts2.shape)\n",
        "post_ai_counts2['rank_chats'] = post_ai_counts2.groupby(['chat_month_date'])['count_chats'].rank(\n",
        "        ascending=False, method='min')\n",
        "\n",
        "post_ai_counts2['rank_duration'] = post_ai_counts2.groupby(['chat_month_date'])['duration_minutes'].rank(\n",
        "        ascending=True, method='min')\n",
        "post_ai_counts2['rank_resolution'] = post_ai_counts2.groupby(['chat_month_date'])['flag_resolved'].rank(\n",
        "        ascending=False, method='min')\n",
        "## break thse into buckets by month, quarters\n",
        "#df.groupby('country')[['value']].transform(lambda x: pd.cut(x, bins = 2).astype(str)\n",
        "post_ai_counts2['quantile_chat_ranks'] = post_ai_counts2.groupby('chat_month_date')[\n",
        "        'count_chats'].transform(lambda x: pd.qcut(x, q=5, labels=['q0', 'q1', 'q2', 'q3', 'q4']))\n",
        "post_ai_counts2['res_per_hour'] = post_ai_counts2['flag_resolved']/(post_ai_counts2['duration_minutes']/60)\n",
        "\n",
        "post_ai_counts2.to_csv(colab_config.topic_counts_filename, index=False)"
      ],
      "metadata": {
        "id": "idOXXYvdH1IR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}